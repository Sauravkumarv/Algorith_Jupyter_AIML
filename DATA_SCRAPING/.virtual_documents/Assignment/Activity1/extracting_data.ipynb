


import pandas as pd
from bs4 import BeautifulSoup
pages = 1
quotes=[]
while True:
    try:
       
        
        with open(f"quotes_data_page{pages}.html", "r", encoding="utf-8") as f:
            html = f.read()
            soup=BeautifulSoup(html,"lxml")
            name=soup.find_all("div",class_="quote")
            
            for n in name:
                quote=n.find("span",class_="text").get_text(strip=True)
                writer=n.find("small",class_="author").get_text(strip=True)
                tag=[t.get_text(strip=True).lower()
                    for t in (n.find_all("a",class_="tag"))
                    ]
                if "life" in tag:
                    quotes.append([writer,quote,tag])
       
        pages += 1
    

    except FileNotFoundError:
        print("No more pages. Stop.")
        break
quote=pd.DataFrame(quotes,columns=["Writer","Quotes","Tags"])
quote.to_csv("normalized_data.csv",index=False,encoding="utf-8-sig")
