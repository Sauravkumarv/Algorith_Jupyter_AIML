


import pandas as pd
import seaborn as sns
df=pd.read_csv("insurance.csv")
df.head()
df.info()
df.describe()


# Data Preprocessing - Data cleaning
df.drop(["Id"],axis=1,inplace=True) # inplace is remove the column from original dataset
df.head()



df["SalePrice"]=df["SalePrice"].fillna(df["SalePrice"].mean())
df



df.shape


df=df.dropna()
df.isnull().sum()
df.head()



# Data Preprocessing - Encoding (Covered in Supervised ML Part2)
cols = ['MSZoning', 'LotConfig', 'BldgType', 'Exterior1st']
df = pd.get_dummies(df, columns=cols, drop_first=True)



from sklearn.model_selection import train_test_split

X=df.drop(['SalePrice'],axis=1)
Y=df['SalePrice']

X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=0)


X_train.head()


# Train Linear Regression Model
from sklearn.linear_model import LinearRegression

model=LinearRegression()
model.fit(X_train,y_train)


from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.metrics import mean_absolute_percentage_error
import numpy as np

y_pred = model.predict(X_test)

print("R2 Score:", r2_score(y_test, y_pred))
print("MAE:", mean_absolute_error(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))
print(mean_absolute_percentage_error(y_test, y_pred))


# Feature Scaling - to try & improve baseline performance
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

model = LinearRegression()
model.fit(X_train_scaled, y_train)

y_pred = model.predict(X_test_scaled)

print("R2 Score:", r2_score(y_test, y_pred))
print("MAE:", mean_absolute_error(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))
print(mean_absolute_percentage_error(y_test, y_pred))

# To get better results we can try some other regression model 
# & also use techniques like Bagging & Boosting (will cover later).
